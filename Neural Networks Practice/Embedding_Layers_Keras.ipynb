{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding Layers Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIZnVzBhTLvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1d80a11-e810-4928-ba3d-9535a8180e73"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBCAoW3cTUHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define documents\n",
        "docs = ['Well done!',\n",
        "\t\t'Good work',\n",
        "\t\t'Great effort',\n",
        "\t\t'nice work',\n",
        "\t\t'Excellent!',\n",
        "\t\t'Weak',\n",
        "\t\t'Poor effort!',\n",
        "\t\t'not good',\n",
        "\t\t'poor work',\n",
        "\t\t'Could have done better.']\n",
        "# define class labels\n",
        "labels = array([1,1,1,1,1,0,0,0,0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apT7pjSoTimv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7d0d2c9-a45d-40fd-8ff2-ddcefc18c30f"
      },
      "source": [
        "# integer encode the documents\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "model.fit(padded_docs, labels, epochs=50)\n",
        "# evaluate the model\n",
        "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0817 10:19:29.133260 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0817 10:19:29.190863 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0817 10:19:29.198381 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0817 10:19:29.268959 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0817 10:19:29.292493 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0817 10:19:29.301294 140284342130560 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[11, 49], [38, 40], [40, 48], [35, 40], [1], [9], [49, 48], [24, 38], [49, 40], [8, 37, 49, 36]]\n",
            "[[11 49  0  0]\n",
            " [38 40  0  0]\n",
            " [40 48  0  0]\n",
            " [35 40  0  0]\n",
            " [ 1  0  0  0]\n",
            " [ 9  0  0  0]\n",
            " [49 48  0  0]\n",
            " [24 38  0  0]\n",
            " [49 40  0  0]\n",
            " [ 8 37 49 36]]\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4, 8)              400       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               8448      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 41,873\n",
            "Trainable params: 41,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0817 10:19:29.561578 140284342130560 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "10/10 [==============================] - 1s 79ms/step - loss: 0.6934 - acc: 0.5000\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 943us/step - loss: 0.6909 - acc: 0.8000\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 270us/step - loss: 0.6883 - acc: 0.8000\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 471us/step - loss: 0.6856 - acc: 0.8000\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 442us/step - loss: 0.6830 - acc: 0.8000\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 525us/step - loss: 0.6803 - acc: 0.8000\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 441us/step - loss: 0.6774 - acc: 0.8000\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 383us/step - loss: 0.6741 - acc: 0.8000\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 238us/step - loss: 0.6704 - acc: 0.8000\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 260us/step - loss: 0.6663 - acc: 0.8000\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 263us/step - loss: 0.6618 - acc: 0.8000\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 220us/step - loss: 0.6568 - acc: 0.8000\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 404us/step - loss: 0.6512 - acc: 0.8000\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 551us/step - loss: 0.6450 - acc: 0.9000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 400us/step - loss: 0.6380 - acc: 0.9000\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 181us/step - loss: 0.6302 - acc: 0.9000\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 167us/step - loss: 0.6215 - acc: 0.9000\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 175us/step - loss: 0.6120 - acc: 0.9000\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 191us/step - loss: 0.6014 - acc: 0.9000\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 200us/step - loss: 0.5898 - acc: 0.9000\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 178us/step - loss: 0.5770 - acc: 0.9000\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 172us/step - loss: 0.5629 - acc: 0.9000\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 150us/step - loss: 0.5477 - acc: 1.0000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 258us/step - loss: 0.5312 - acc: 1.0000\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 234us/step - loss: 0.5135 - acc: 1.0000\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 203us/step - loss: 0.4947 - acc: 1.0000\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 211us/step - loss: 0.4746 - acc: 1.0000\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 173us/step - loss: 0.4533 - acc: 1.0000\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 273us/step - loss: 0.4308 - acc: 1.0000\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 284us/step - loss: 0.4072 - acc: 1.0000\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 321us/step - loss: 0.3827 - acc: 1.0000\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 283us/step - loss: 0.3575 - acc: 1.0000\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 305us/step - loss: 0.3318 - acc: 1.0000\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 231us/step - loss: 0.3057 - acc: 1.0000\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 212us/step - loss: 0.2797 - acc: 1.0000\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 262us/step - loss: 0.2538 - acc: 1.0000\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 185us/step - loss: 0.2285 - acc: 1.0000\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 178us/step - loss: 0.2040 - acc: 1.0000\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 497us/step - loss: 0.1805 - acc: 1.0000\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 262us/step - loss: 0.1583 - acc: 1.0000\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 254us/step - loss: 0.1376 - acc: 1.0000\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 385us/step - loss: 0.1185 - acc: 1.0000\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 244us/step - loss: 0.1013 - acc: 1.0000\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 388us/step - loss: 0.0859 - acc: 1.0000\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 259us/step - loss: 0.0723 - acc: 1.0000\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 388us/step - loss: 0.0606 - acc: 1.0000\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 252us/step - loss: 0.0505 - acc: 1.0000\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 235us/step - loss: 0.0420 - acc: 1.0000\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 213us/step - loss: 0.0349 - acc: 1.0000\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 288us/step - loss: 0.0290 - acc: 1.0000\n",
            "Accuracy: 100.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pvnEonhTmLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "63486aa7-0f96-4465-ffef-e86a7dd7c120"
      },
      "source": [
        "import numpy as np\n",
        "docs = ['great nice', 'poor effort']\n",
        "vocab_size = 50\n",
        "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
        "print(encoded_docs)\n",
        "# pad documents to a max length of 4 words\n",
        "max_length = 4\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "print(padded_docs)\n",
        "model.predict(padded_docs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[40, 35], [49, 48]]\n",
            "[[40 35  0  0]\n",
            " [49 48  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79063237],\n",
              "       [0.03938819]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZGCvH9RFVZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}