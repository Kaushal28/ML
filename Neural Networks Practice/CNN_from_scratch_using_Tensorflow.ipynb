{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN from scratch using Tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDXv68N0oVAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMJoRkMPofZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "750b967d-96ca-4825-9827-f2532f5c3df1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi8lq3u2ohn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp /content/drive/My\\ Drive/Datasets/digit-recognizer.zip /content\n",
        "# !unzip digit-recognizer.zip\n",
        "# ! rm -rf sample_data digit-recognizer.zip\n",
        "# !rm -rf test.csv\n",
        "# !rm -rf sample_submission.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Whf9HHo2gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wmv9etspO4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data_df.drop(['label'], axis = 1)\n",
        "Y = data_df['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTMCLCEvq0UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the input images\n",
        "X = X.to_numpy() / 255.0\n",
        "# One hot encode the labels\n",
        "Y = pd.get_dummies(Y.to_numpy()).to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo2tYdBqza-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Resize in shape of (m, h, w, c) for CNN\n",
        "X = X.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRN4pNA2pR_t",
        "colab_type": "code",
        "outputId": "debdb896-9161-4145-e925-a27923f7d57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print (X.shape)\n",
        "print (Y.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 28, 28, 1)\n",
            "(42000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx8jLyyrqwrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbxmcMNyrFEm",
        "colab_type": "code",
        "outputId": "a7dd7abc-b2ff-4943-a335-fff09f9d600a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "print (Y_train.shape)\n",
        "print (X_test.shape)\n",
        "print (Y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36960, 28, 28, 1)\n",
            "(36960, 10)\n",
            "(5040, 28, 28, 1)\n",
            "(5040, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6VmbaerHtNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes, image_size, n_channels = 10, 28, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnBQbNV4rcuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_relu(inp, filter_size, n_filter):\n",
        "    weights = tf.get_variable(name = 'weights', shape = [filter_size, filter_size, inp.shape[3], n_filter], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases', shape = [n_filter], initializer = tf.zeros_initializer())\n",
        "    conv = tf.nn.conv2d(input = inp, filter = weights, strides = [1, 1, 1, 1], padding = 'SAME')\n",
        "    return tf.nn.relu(tf.add(conv, biases))  \n",
        "\n",
        "def max_pool(inp, filter_size):\n",
        "    return tf.nn.max_pool(value=inp, ksize=[1, filter_size, filter_size, 1], strides=[1, filter_size, filter_size, 1], padding = 'SAME')\n",
        "\n",
        "def fully_connected(inp, n_neurons):\n",
        "    weights = tf.get_variable(name = 'weights', shape = [inp.shape[1], n_neurons], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases', shape = [n_neurons], initializer=tf.zeros_initializer())\n",
        "\n",
        "    return tf.add(tf.matmul(inp, weights), biases)\n",
        "\n",
        "def fully_connected_relu(inp, n_neurons):\n",
        "    return tf.nn.relu(fully_connected(inp, n_neurons))\n",
        "\n",
        "def dropout(inp, dropout_rate = 0.2):\n",
        "    return tf.nn.dropout(x=inp, rate=dropout_rate, seed = 28) # rate is 1 - keep_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gRgAFVdG1J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get placeholders for X and Y with batch size as variable parameter\n",
        "def get_placeholders():\n",
        "    X = tf.placeholder(name='X', shape=[None, image_size, image_size, n_channels], dtype=tf.float32)\n",
        "    Y = tf.placeholder(name='Y', shape = [None, n_classes], dtype=tf.float32) # One hot encoded size of Y\n",
        "    is_training = tf.placeholder(name='is_training', dtype=tf.bool)\n",
        "    return X, Y, is_training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jEa4F7K_y3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_forward_propagate(data, is_training):\n",
        "\n",
        "    # Adding first convolution layer\n",
        "    with tf.variable_scope(name_or_scope='conv0', reuse=tf.AUTO_REUSE):\n",
        "        conv = conv_relu(data, filter_size=3, n_filter=64)\n",
        "        pool = max_pool(conv, filter_size = 2)\n",
        "        # pool = tf.cond(is_training, lambda: dropout(pool, 0.2), lambda: pool)\n",
        "        \n",
        "    # # Adding second convolution layer\n",
        "    # with tf.variable_scope(name_or_scope='conv1', reuse=tf.AUTO_REUSE):\n",
        "    #     conv = conv_relu(pool, filter_size = 2, n_filter = 64)\n",
        "    #     pool = max_pool(conv, filter_size = 2)\n",
        "    #     # pool = tf.cond(is_training, lambda: dropout(pool, 0.2), lambda: pool)\n",
        "\n",
        "    # # Adding third convolution layer\n",
        "    # with tf.variable_scope(name_or_scope='conv2'):\n",
        "    #     conv = conv_relu(pool, filter_size=2, n_filter=128)\n",
        "    #     pool = max_pool(conv, filter_size=2)\n",
        "    #     # pool = tf.cond(is_training, lambda: dropout(pool, 0.2), lambda: pool)\n",
        "\n",
        "    # Flatten the output for inject it in fully connected layer\n",
        "    shapes = pool.get_shape().as_list()\n",
        "    flattened = tf.reshape(pool, [-1, shapes[1] * shapes[2] * shapes[3]])\n",
        "    \n",
        "    # Adding fully connected layer of size 16\n",
        "    with tf.variable_scope(name_or_scope='fc0', reuse=tf.AUTO_REUSE):\n",
        "        fc_relu = fully_connected_relu(flattened, 32)\n",
        "    \n",
        "    # # Adding another fully connected layer with 16 neurons\n",
        "    # with tf.variable_scope(name_or_scope='fc1', reuse=tf.AUTO_REUSE):\n",
        "    #     fc_relu = fully_connected_relu(fc_relu, 16)\n",
        "\n",
        "    # Output layer with 10 neurons (n_classes = 10)\n",
        "    with tf.variable_scope(name_or_scope='output', reuse=tf.AUTO_REUSE):\n",
        "        logits = fully_connected(fc_relu, n_classes)\n",
        "    \n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZNL30YLI_T1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_loss(labels, logits):\n",
        "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyeGAJWIut7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_minibatches(X, Y, minibatch_size = 64, seed = 28):\n",
        "    import math\n",
        "    # First set the seed\n",
        "    np.random.seed(seed)\n",
        "    m = X.shape[0]\n",
        "    minibatches = []\n",
        "\n",
        "    # Then get the permutation of indices and using that, shuffel X and Y\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    X = X[permutation, :, :, :]\n",
        "    Y = Y[permutation, :].reshape(m, Y.shape[1])\n",
        "\n",
        "    # Now get minibatches from shuffeled X and Y\n",
        "    n_complete_minibatches = math.floor(m / minibatch_size)\n",
        "\n",
        "    # Get all complete minibatches\n",
        "    for index in range(n_complete_minibatches):\n",
        "        minibatch_X = X[index * minibatch_size : (index + 1) * minibatch_size, :, :, :]\n",
        "        minibatch_Y = Y[index * minibatch_size : (index + 1) * minibatch_size, :]\n",
        "        minibatches.append((minibatch_X, minibatch_Y))\n",
        "\n",
        "    # Now handle the case of last incomplete minibatch\n",
        "    if not (m % minibatch_size == 0):\n",
        "        minibatch_X = X[n_complete_minibatches * minibatch_size: , :, :, :]\n",
        "        minibatch_Y = Y[n_complete_minibatches * minibatch_size: , :]\n",
        "        minibatches.append((minibatch_X, minibatch_Y))\n",
        "\n",
        "    return minibatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnf7IZaFY5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model(X_train, Y_train, X_test, Y_test, learning_rate = 0.02, n_epochs = 10, minibatch_size = 32):\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    X, Y, is_training = get_placeholders()\n",
        "    \n",
        "    # Forward propagate through CNN\n",
        "    logits = cnn_forward_propagate(X, is_training=is_training)\n",
        "\n",
        "    # Calculate the cost\n",
        "    cost = calculate_loss(Y, logits)\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Initialize all tf variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    costs, m = [], X_train.shape[0]\n",
        "\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        \n",
        "        for epoch in range(n_epochs):\n",
        "            n_minibatches, batch_cost = m // minibatch_size, 0\n",
        "            minibatches = get_random_minibatches(X_train, Y_train, minibatch_size)\n",
        "            for minibatch in minibatches:\n",
        "                xb, yb = minibatch\n",
        "                _, minibatch_cost = session.run([optimizer, cost], feed_dict = {X: xb, Y: yb, is_training: True})\n",
        "                batch_cost += minibatch_cost / n_minibatches\n",
        "            costs.append(batch_cost)\n",
        "            print (f'Costs after {epoch} epochs: {batch_cost}')\n",
        "        \n",
        "        x1 = tf.placeholder(name = 'x1', shape = [None, 28, 28, 1], dtype = tf.float32)\n",
        "        y1 = tf.placeholder(name = 'y1', shape = [None, 10], dtype = tf.float32)\n",
        "        \n",
        "        correct_preds = tf.equal(tf.argmax(cnn_forward_propagate(x1, tf.constant(False, dtype=tf.bool)), axis = 1), tf.argmax(y1, axis = 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_preds, dtype= 'float'))\n",
        "        train_acc = session.run(accuracy, feed_dict = {x1: X_train, y1: Y_train})\n",
        "        test_acc = session.run(accuracy, feed_dict = {x1: X_test, y1: Y_test})\n",
        "\n",
        "        print (f'Training set Accuracy: {train_acc * 100}')\n",
        "        print (f'Dev set Accuracy: {test_acc * 100}')\n",
        "\n",
        "        return costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fN0F24clBSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "42c2a4d2-48b7-4fdb-f381-ee48e33ddcd1"
      },
      "source": [
        "costs = cnn_model(X_train, Y_train, X_test, Y_test, learning_rate=0.02)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Costs after 0 epochs: 0.2106031302860595\n",
            "Costs after 1 epochs: 0.11452936458479998\n",
            "Costs after 2 epochs: 0.10847841451986238\n",
            "Costs after 3 epochs: 0.09341808373282345\n",
            "Costs after 4 epochs: 0.09205394123252807\n",
            "Costs after 5 epochs: 0.08836513661407262\n",
            "Costs after 6 epochs: 0.082242335551657\n",
            "Costs after 7 epochs: 0.09018467126903362\n",
            "Costs after 8 epochs: 0.08045991059465857\n",
            "Costs after 9 epochs: 0.08266968180889328\n",
            "Training set Accuracy: 98.82846474647522\n",
            "Dev set Accuracy: 96.50793671607971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww0bqlovzfNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "140e1990-ad2a-4f3c-e185-f57db2bd7fdd"
      },
      "source": [
        "plt.plot(costs)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}