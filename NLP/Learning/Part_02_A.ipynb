{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Part-02-A.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "aBNFqPeeYIOb"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mtXuJy6YIMp",
        "colab_type": "text"
      },
      "source": [
        "# Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqdUmg5UYIMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = 'http://www.gutenberg.org/ebooks/1661.txt.utf-8'\n",
        "file_name = 'sherlock.txt'\n",
        "!rm -rf sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FehIjKrYIMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "# Download the file from `url` and save it locally under `file_name`:\n",
        "data = requests.get(url)\n",
        "with open(file_name, 'w+') as out_file:\n",
        "    out_file.write(data.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w5S0vw-YIM0",
        "colab_type": "code",
        "outputId": "c1b50e89-a38c-4c29-cc77-431b05095f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sherlock.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vTWmUj7YIM6",
        "colab_type": "code",
        "outputId": "e9f73743-f1d4-4234-8dc5-09577e294feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!head -2 sherlock.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle\r\n",
            "\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKyKZlXqYIM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove the first 33 lines inplace from the file\n",
        "!sed -i 1,33d sherlock.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw887aBtYIND",
        "colab_type": "code",
        "outputId": "24d601eb-692c-4fe5-9b0d-65c6d8e7abc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!head -5 sherlock.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THE ADVENTURES OF SHERLOCK HOLMES\r\n",
            "\r\n",
            "by\r\n",
            "\r\n",
            "SIR ARTHUR CONAN DOYLE\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiKAa-bnYINH",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5R36PcrYINI",
        "colab_type": "code",
        "outputId": "8b27fbbf-45b3-4ef8-bf13-8e2fb2affa87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#let's the load data to RAM\n",
        "text = open(file_name, 'r', encoding='utf-8').read()  # note that I add an encoding='utf-8' parameter to preserve information\n",
        "print(text[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THE A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiEWFPPeYINM",
        "colab_type": "code",
        "outputId": "8f63a521-ce76-49fe-9b18-24a4290bdf23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The file is loaded as datatype: {type(text)} and has {len(text)} characters in it')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The file is loaded as datatype: <class 'str'> and has 581204 characters in it\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TpHlfiYINQ",
        "colab_type": "text"
      },
      "source": [
        "### Exploring Loaded Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZTn0MGzYINR",
        "colab_type": "code",
        "outputId": "a609a2f3-3514-4c14-863b-ef0a03558028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# how many unique characters do we see? \n",
        "# For reference, ASCII has 127 characters in it - so we expect this to have at most 127 characters\n",
        "unique_chars = list(set(text))\n",
        "unique_chars.sort()\n",
        "print(unique_chars)\n",
        "print(f'There are {len(unique_chars)} unique characters, including both ASCII and Unicode character')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'â', 'è', 'é']\n",
            "There are 85 unique characters, including both ASCII and Unicode character\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_8B3DxcYINX",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization \n",
        "\n",
        "### Split by Whitespace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLoKnBo3YINY",
        "colab_type": "code",
        "outputId": "9254aee0-2ef8-4ad1-bcc4-e2b182ec85a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = text.split()\n",
        "print(len(words))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh0iEH7CYINd",
        "colab_type": "code",
        "outputId": "5c645dd3-6035-483e-afda-7799d7608094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(words[90:200])  #start with the first chapeter, ignoring the index for now"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['To', 'Sherlock', 'Holmes', 'she', 'is', 'always', 'THE', 'woman.', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name.', 'In', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex.', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler.', 'All', 'emotions,', 'and', 'that', 'one', 'particularly,', 'were', 'abhorrent', 'to', 'his', 'cold,', 'precise', 'but', 'admirably', 'balanced', 'mind.', 'He', 'was,', 'I', 'take', 'it,', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen,', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position.', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passions,', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer.', 'They', 'were', 'admirable', 'things', 'for']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3Ax1Sm9YINk",
        "colab_type": "code",
        "outputId": "7928b160-eca9-4e2a-dd84-e27c7db1da67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let's look at another example: \n",
        "'red-headed woman on the street'.split()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red-headed', 'woman', 'on', 'the', 'street']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4hgCD9nYINp",
        "colab_type": "text"
      },
      "source": [
        "### Split by Word Extraction\n",
        "**Introducing Regex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8POhvlJZYINr",
        "colab_type": "code",
        "outputId": "4e3ddabb-3302-4386-9f61-05126b4e9cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "re.split('\\W+', 'Words, words, words.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Words', 'words', 'words', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny6iwXT8YINv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_alphanumeric = re.split('\\W+', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIkz172fYINy",
        "colab_type": "code",
        "outputId": "9e6b32f1-91b5-4e0a-b09c-789632a3c66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(words_alphanumeric), len(words)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109111, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vsq6tpKYIN2",
        "colab_type": "code",
        "outputId": "2128214d-2c6a-49e6-af51-42b62e6ad903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(words_alphanumeric[90:200])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BOHEMIA', 'I', 'To', 'Sherlock', 'Holmes', 'she', 'is', 'always', 'THE', 'woman', 'I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', 'In', 'his', 'eyes', 'she', 'eclipses', 'and', 'predominates', 'the', 'whole', 'of', 'her', 'sex', 'It', 'was', 'not', 'that', 'he', 'felt', 'any', 'emotion', 'akin', 'to', 'love', 'for', 'Irene', 'Adler', 'All', 'emotions', 'and', 'that', 'one', 'particularly', 'were', 'abhorrent', 'to', 'his', 'cold', 'precise', 'but', 'admirably', 'balanced', 'mind', 'He', 'was', 'I', 'take', 'it', 'the', 'most', 'perfect', 'reasoning', 'and', 'observing', 'machine', 'that', 'the', 'world', 'has', 'seen', 'but', 'as', 'a', 'lover', 'he', 'would', 'have', 'placed', 'himself', 'in', 'a', 'false', 'position', 'He', 'never', 'spoke', 'of', 'the', 'softer', 'passions', 'save', 'with', 'a', 'gibe', 'and', 'a', 'sneer', 'They', 'were', 'admirable']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gw6g8GYYIN6",
        "colab_type": "code",
        "outputId": "3d41872d-5656-4be8-ca04-fc1d6afcce2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# words_break = re.split('\\W+', \":::::And for the second time of asking, when\")\n",
        "# print(words_break)\n",
        "print(' '.join(re.split('\\W+', \"::::::And for the second time of asking, when\")))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " And for the second time of asking when\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPBME9nXYIN9",
        "colab_type": "text"
      },
      "source": [
        "### spaCy for Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUM_tBXHYIN_",
        "colab_type": "code",
        "outputId": "2efc1b51-1b70-4534-faeb-9151b9525a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 740 ms, sys: 197 ms, total: 937 ms\n",
            "Wall time: 3.73 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywmWoA1lYIOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4ayU759YIOJ",
        "colab_type": "code",
        "outputId": "bbd0885b-9c9f-4fd5-a296-cdb08cc69d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(list(doc)[150:200])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[whole, of, her, sex, ., It, was, not, that, he, felt, \n",
            ", any, emotion, akin, to, love, for, Irene, Adler, ., All, emotions, ,, and, that, \n",
            ", one, particularly, ,, were, abhorrent, to, his, cold, ,, precise, but, \n",
            ", admirably, balanced, mind, ., He, was, ,, I, take, it, ,]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXfBgc1-YIOP",
        "colab_type": "text"
      },
      "source": [
        "Conveniently, spaCy tokenizes all *punctuations and words* and returned those as individual tokens as well. Let's try the example which we didn't like earlier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6srxj1FxYIOQ",
        "colab_type": "code",
        "outputId": "fb752390-306a-4eed-fcb8-eea5b7819d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = nlp(\"Isn't he coming home for dinner with the red-headed girl?\")\n",
        "print([token for token in words])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Is, n't, he, coming, home, for, dinner, with, the, red, -, headed, girl, ?]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ0SVRRdYIOY",
        "colab_type": "code",
        "outputId": "b257e666-135c-47ff-80ca-d7b778340f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "sentences = list(doc.sents)\n",
        "print(sentences[35:45])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(for I had now returned to\n",
            "civil practice), when my way led me through Baker Street., As I\n",
            "passed the well-remembered door, which must always be associated\n",
            "in my mind with my wooing, and with the dark incidents of the\n",
            "Study in Scarlet, I was seized with a keen desire to see Holmes\n",
            "again, and to know how he was employing his extraordinary powers.\n",
            ", His rooms were brilliantly lit, and, even as I looked up, I saw\n",
            "his tall, spare figure pass twice in a dark silhouette against\n",
            "the blind., He was pacing the room swiftly, eagerly, with his head\n",
            "sunk upon his chest and his hands clasped behind him., To me, who\n",
            "knew his every mood and habit, his attitude and manner told their\n",
            "own story., He was at work again., He had risen out of his\n",
            "drug-created dreams and was hot upon the scent of some new\n",
            "problem., I rang the bell and was shown up to the chamber which\n",
            "had formerly been in part my own.\n",
            "\n",
            ", His manner was not effusive., It seldom was; but he was glad, I\n",
            "think, to see me.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBNFqPeeYIOb",
        "colab_type": "text"
      },
      "source": [
        "#### STOP WORD REMOVAL & CASE CHANGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnJ5Xli0YIOd",
        "colab_type": "text"
      },
      "source": [
        "spaCy has already marked each token as a stop word or not and stored it in `is_stop` attribute of each token. This makes it very handy for text cleaning. Let's take a quick look: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lso01XURYIOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_example = \"the AI/AGI uprising cannot happen without the progress of NLP\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szzP2YnTYIOj",
        "colab_type": "code",
        "outputId": "dd683f7a-3e3e-4779-e853-3ef49c5fa47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "[(token, token.is_stop, token.is_punct) for token in nlp(sentence_example)]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(the, True, False),\n",
              " (AI, False, False),\n",
              " (/, False, True),\n",
              " (AGI, False, False),\n",
              " (uprising, False, False),\n",
              " (can, True, False),\n",
              " (not, True, False),\n",
              " (happen, False, False),\n",
              " (without, True, False),\n",
              " (the, True, False),\n",
              " (progress, False, False),\n",
              " (of, True, False),\n",
              " (NLP, False, False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HalPF2SgYIOs",
        "colab_type": "code",
        "outputId": "4dc5234b-cb53-403a-e649-91ed09dc804e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "for token in doc[:5]:\n",
        "    print(token, token.is_stop, token.is_punct)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THE True False\n",
            "ADVENTURES False False\n",
            "OF True False\n",
            "SHERLOCK False False\n",
            "HOLMES False False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNMihJElYIOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_lower = text.lower()  # native python function\n",
        "doc_lower = nlp(text_lower)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGVyS85oYIOz",
        "colab_type": "code",
        "outputId": "d87e8310-6e6a-4243-cc5c-a2dd211bb3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "for token in doc_lower[:5]:\n",
        "    print(token, token.is_stop)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the True\n",
            "adventures False\n",
            "of True\n",
            "sherlock False\n",
            "holmes False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKX11aEaYIO3",
        "colab_type": "code",
        "outputId": "6aed1d54-6a50-4c77-dde9-0d1f0f5e964a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "f'spaCy has a dictionary of {len(list(STOP_WORDS))} stop words'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spaCy has a dictionary of 326 stop words'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHfb3U7UYIO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "domain_stop_words = [\"NLP\", \"Processing\", \"AGI\"]\n",
        "for word in domain_stop_words:\n",
        "    STOP_WORDS.add(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mwi3YQFmo0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1f15e61-28b5-41a4-d85d-d581fb4eae5d"
      },
      "source": [
        "f'spaCy has a dictionary of {len(list(STOP_WORDS))} stop words'"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spaCy has a dictionary of 329 stop words'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptNwiaL20czs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "8b1b34a6-20e9-439c-c2fe-2ce9434e6705"
      },
      "source": [
        "# !pip install --upgrade spacy\n",
        "# spacy.__version__\n",
        "nlp.vocab['NLP'].is_stop = True\n",
        "print(nlp.vocab['NLP'].is_stop)\n",
        "print(nlp.vocab['uprising'].is_stop)\n",
        "f'spaCy has a dictionary of {len(list(STOP_WORDS))} stop words'\n",
        "nlp.vocab['uprising'].is_stop = True\n",
        "print (f'spaCy has a dictionary of {len(list(STOP_WORDS))} stop words')\n",
        "print( 'uprising' in STOP_WORDS)\n",
        "print(nlp.vocab['uprising'].is_stop)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "spaCy has a dictionary of 329 stop words\n",
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7lYyNxEmvzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "313c7c3e-d5a6-4a6a-b2b4-ee9d63cc85f1"
      },
      "source": [
        "'NLP' in STOP_WORDS"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgvvak8ZAETK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qimtDVpFYIPA",
        "colab_type": "code",
        "outputId": "7b41e202-2d97-40d1-fb96-0a2d0e430350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "[(token, token.is_stop, token.is_punct) for token in nlp(\"the AI/AGI uprising cannot happen without the progress of NLP\")]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(the, True, False),\n",
              " (AI, False, False),\n",
              " (/, False, True),\n",
              " (AGI, False, False),\n",
              " (uprising, False, False),\n",
              " (can, True, False),\n",
              " (not, True, False),\n",
              " (happen, False, False),\n",
              " (without, True, False),\n",
              " (the, True, False),\n",
              " (progress, False, False),\n",
              " (of, True, False),\n",
              " (NLP, False, False)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO9TkzixYIPE",
        "colab_type": "code",
        "outputId": "3553ce9c-ba7c-4a13-b16c-d38281cec382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[str(token) for token in nlp(sentence_example) if not token.is_stop and not token.is_punct]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI', 'AGI', 'uprising', 'happen', 'progress', 'NLP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3oTplwAYIPI",
        "colab_type": "code",
        "outputId": "c4cfaac7-bf65-400c-f1fa-ba6c71cc30d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[str(token) for token in nlp(sentence_example) if not token.is_stop]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI', '/', 'AGI', 'uprising', 'happen', 'progress', 'NLP']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhspAI_wYIPS",
        "colab_type": "text"
      },
      "source": [
        "## Stemming and Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lq8e9vnIYIPT",
        "colab_type": "text"
      },
      "source": [
        "### spaCy for Lemmatization\n",
        "**spaCy only supports lemmatization** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wca0A_rDYIPU",
        "colab_type": "text"
      },
      "source": [
        "An underscore at end, such as `lemma_` tells spaCy we are looking for something which is human readable. spaCy stores the internal hash or identifier which spaCy stores in `token.lemma`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv6FN-hoYIPV",
        "colab_type": "code",
        "outputId": "2ef11775-6bb7-4cd8-8cb5-524fc5d920e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "lemma_sentence_example = \"Their Apples & Banana fruit salads are amazing. Would you like meeting me at the cafe?\"\n",
        "[(token, token.lemma_, token.lemma, token.pos_ ) for token in nlp(lemma_sentence_example)]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Their, '-PRON-', 561228191312463089, 'DET'),\n",
              " (Apples, 'Apples', 9297668116247400838, 'PROPN'),\n",
              " (&, '&', 15473034735919704609, 'CCONJ'),\n",
              " (Banana, 'Banana', 7617506991971869807, 'PROPN'),\n",
              " (fruit, 'fruit', 17674554054627885835, 'NOUN'),\n",
              " (salads, 'salad', 16382906660984395826, 'NOUN'),\n",
              " (are, 'be', 10382539506755952630, 'VERB'),\n",
              " (amazing, 'amazing', 12968186374132960503, 'ADJ'),\n",
              " (., '.', 12646065887601541794, 'PUNCT'),\n",
              " (Would, 'Would', 10299253490465169573, 'VERB'),\n",
              " (you, '-PRON-', 561228191312463089, 'PRON'),\n",
              " (like, 'like', 18194338103975822726, 'VERB'),\n",
              " (meeting, 'meet', 6880656908171229526, 'VERB'),\n",
              " (me, '-PRON-', 561228191312463089, 'PRON'),\n",
              " (at, 'at', 11667289587015813222, 'ADP'),\n",
              " (the, 'the', 7425985699627899538, 'DET'),\n",
              " (cafe, 'cafe', 10569699879655997926, 'NOUN'),\n",
              " (?, '?', 8205403955989537350, 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBVhRVIl5-rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}