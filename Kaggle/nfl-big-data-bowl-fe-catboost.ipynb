{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2020/train.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from kaggle.competitions import nflrush\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "import gc, re\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.48 s, sys: 1.87 s, total: 9.36 s\n",
      "Wall time: 9.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training dataset: (509762, 49)\n"
     ]
    }
   ],
   "source": [
    "print (f'Shape of training dataset: {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameId</th>\n",
       "      <th>PlayId</th>\n",
       "      <th>Team</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>S</th>\n",
       "      <th>A</th>\n",
       "      <th>Dis</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Dir</th>\n",
       "      <th>...</th>\n",
       "      <th>Week</th>\n",
       "      <th>Stadium</th>\n",
       "      <th>Location</th>\n",
       "      <th>StadiumType</th>\n",
       "      <th>Turf</th>\n",
       "      <th>GameWeather</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>WindDirection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>73.91</td>\n",
       "      <td>34.84</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.40</td>\n",
       "      <td>81.99</td>\n",
       "      <td>177.18</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>74.67</td>\n",
       "      <td>32.64</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27.61</td>\n",
       "      <td>198.70</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>74.00</td>\n",
       "      <td>33.20</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.01</td>\n",
       "      <td>202.73</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>71.46</td>\n",
       "      <td>27.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>359.77</td>\n",
       "      <td>105.64</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017090700</td>\n",
       "      <td>20170907000118</td>\n",
       "      <td>away</td>\n",
       "      <td>69.32</td>\n",
       "      <td>35.42</td>\n",
       "      <td>1.82</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.16</td>\n",
       "      <td>12.63</td>\n",
       "      <td>164.31</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Gillette Stadium</td>\n",
       "      <td>Foxborough, MA</td>\n",
       "      <td>Outdoor</td>\n",
       "      <td>Field Turf</td>\n",
       "      <td>Clear and warm</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8</td>\n",
       "      <td>SW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       GameId          PlayId  Team      X      Y     S     A   Dis  \\\n",
       "0  2017090700  20170907000118  away  73.91  34.84  1.69  1.13  0.40   \n",
       "1  2017090700  20170907000118  away  74.67  32.64  0.42  1.35  0.01   \n",
       "2  2017090700  20170907000118  away  74.00  33.20  1.22  0.59  0.31   \n",
       "3  2017090700  20170907000118  away  71.46  27.70  0.42  0.54  0.02   \n",
       "4  2017090700  20170907000118  away  69.32  35.42  1.82  2.43  0.16   \n",
       "\n",
       "   Orientation     Dir  ...  Week           Stadium        Location  \\\n",
       "0        81.99  177.18  ...     1  Gillette Stadium  Foxborough, MA   \n",
       "1        27.61  198.70  ...     1  Gillette Stadium  Foxborough, MA   \n",
       "2         3.01  202.73  ...     1  Gillette Stadium  Foxborough, MA   \n",
       "3       359.77  105.64  ...     1  Gillette Stadium  Foxborough, MA   \n",
       "4        12.63  164.31  ...     1  Gillette Stadium  Foxborough, MA   \n",
       "\n",
       "   StadiumType        Turf     GameWeather Temperature Humidity  WindSpeed  \\\n",
       "0      Outdoor  Field Turf  Clear and warm        63.0     77.0          8   \n",
       "1      Outdoor  Field Turf  Clear and warm        63.0     77.0          8   \n",
       "2      Outdoor  Field Turf  Clear and warm        63.0     77.0          8   \n",
       "3      Outdoor  Field Turf  Clear and warm        63.0     77.0          8   \n",
       "4      Outdoor  Field Turf  Clear and warm        63.0     77.0          8   \n",
       "\n",
       "   WindDirection  \n",
       "0             SW  \n",
       "1             SW  \n",
       "2             SW  \n",
       "3             SW  \n",
       "4             SW  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GameId', 'PlayId', 'Team', 'X', 'Y', 'S', 'A', 'Dis', 'Orientation',\n",
       "       'Dir', 'NflId', 'DisplayName', 'JerseyNumber', 'Season', 'YardLine',\n",
       "       'Quarter', 'GameClock', 'PossessionTeam', 'Down', 'Distance',\n",
       "       'FieldPosition', 'HomeScoreBeforePlay', 'VisitorScoreBeforePlay',\n",
       "       'NflIdRusher', 'OffenseFormation', 'OffensePersonnel',\n",
       "       'DefendersInTheBox', 'DefensePersonnel', 'PlayDirection', 'TimeHandoff',\n",
       "       'TimeSnap', 'Yards', 'PlayerHeight', 'PlayerWeight', 'PlayerBirthDate',\n",
       "       'PlayerCollegeName', 'Position', 'HomeTeamAbbr', 'VisitorTeamAbbr',\n",
       "       'Week', 'Stadium', 'Location', 'StadiumType', 'Turf', 'GameWeather',\n",
       "       'Temperature', 'Humidity', 'WindSpeed', 'WindDirection'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Field Turf', 'A-Turf Titan', 'Grass', 'UBU Sports Speed S5-M',\n",
       "       'Artificial', 'DD GrassMaster', 'Natural Grass',\n",
       "       'UBU Speed Series-S5-M', 'FieldTurf', 'FieldTurf 360',\n",
       "       'Natural grass', 'grass', 'Natural', 'Artifical', 'FieldTurf360',\n",
       "       'Naturall Grass', 'Field turf', 'SISGrass',\n",
       "       'Twenty-Four/Seven Turf', 'natural grass'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Turf.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each PlayId has data of all 22 players and there are 23171 plays given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to reduce the memory usage\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print(f'Mem. usage decreased to {end_mem} Mb ({100 * (start_mem - end_mem) / start_mem}% reduction)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_specific_cols(col_names):\n",
    "    cols, total_players = [], 22\n",
    "    for col in col_names:\n",
    "        for player in range(total_players):\n",
    "            cols.append(f'{col}_player{player}')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_without_overflow_fast(col):\n",
    "    col /= len(col)\n",
    "    return col.mean() * len(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cyclic_feature(df, col, max_vals):\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col]/max_vals)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col]/max_vals)\n",
    "    del df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timestamp(df, timestamp_col):\n",
    "    df[f'{timestamp_col}Hour'] = np.uint8(df[timestamp_col].dt.hour)\n",
    "    df[f'{timestamp_col}Minute'] = np.uint8(df[timestamp_col].dt.minute)\n",
    "    df[f'{timestamp_col}Second'] = np.uint8(df[timestamp_col].dt.second)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_specific_cols(col_names):\n",
    "    cols, total_players = [], 22\n",
    "    for col in col_names:\n",
    "        for player in range(total_players):\n",
    "            cols.append(f'{col}_player{player}')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_to_inches(player_height):\n",
    "    return int(player_height.split('-')[0]) * 12 + int(player_height.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdate_to_age(bdate):\n",
    "    now = pd.to_datetime('now')\n",
    "    return (now.year - bdate.dt.year) - ((now.month - bdate.dt.month) < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grouping_dict(df, key):\n",
    "    dicts = []\n",
    "    for _, row in df.iterrows():\n",
    "        dicts.append(dict([(pos.split()[1], pos.split()[0]) for (pos) in row[key].split(',')]))\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_playid(df, is_training=True):\n",
    "    \n",
    "    total_players = 22\n",
    "    non_player_features = ['GameId', 'PlayId', 'Season', 'YardLine', 'Quarter', 'GameClock',\n",
    "       'PossessionTeam', 'Down', 'Distance', 'FieldPosition',\n",
    "       'HomeScoreBeforePlay', 'VisitorScoreBeforePlay',\n",
    "       'OffenseFormation', 'OffensePersonnel', 'DefendersInTheBox',\n",
    "       'DefensePersonnel', 'PlayDirection', 'TimeHandoff', 'TimeSnap',\n",
    "       'Yards', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'Week', 'Stadium',\n",
    "       'Location', 'StadiumType', 'Turf', 'GameWeather', 'Temperature',\n",
    "       'Humidity', 'WindSpeed', 'WindDirection', 'NflId']\n",
    "    \n",
    "    if not is_training:\n",
    "        non_player_features.remove('Yards')\n",
    "    \n",
    "    player_features = ['Team', 'X', 'Y', 'S', 'A', 'Dis', 'Orientation', 'Dir',\n",
    "       'DisplayName', 'JerseyNumber', 'PlayerHeight', 'PlayerWeight',\n",
    "       'PlayerBirthDate', 'PlayerCollegeName', 'Position', 'NflIdRusher']\n",
    "    \n",
    "    playids_groups = df.groupby('PlayId').size().keys()\n",
    "    \n",
    "    player_features_columns = []\n",
    "    for feature in player_features:\n",
    "        for player in range(total_players):\n",
    "            player_features_columns.append(f'{feature}_player{player}')\n",
    "    \n",
    "    # first assign non_player features which are common for a single game playid\n",
    "    final_df = pd.DataFrame()\n",
    "    final_df[non_player_features] = df.groupby('PlayId')[non_player_features].first().reset_index(drop=True)\n",
    "    final_df = final_df.reindex(final_df.columns.tolist() + player_features_columns, axis=1)\n",
    "    temp_cols = []\n",
    "    if is_training:\n",
    "        for group in tqdm(playids_groups, position=0, leave=True):\n",
    "            temp_cols.append(df[df['PlayId'] == group][player_features].melt()['value'])\n",
    "    else:\n",
    "        for group in playids_groups:\n",
    "            temp_cols.append(df[df['PlayId'] == group][player_features].melt()['value'])\n",
    "    final_df[player_features_columns] = pd.DataFrame(temp_cols).values\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df, is_training=True, label_encoders={}):\n",
    "    \n",
    "    if is_training:\n",
    "        label_encoders['NflId'] = LabelEncoder()\n",
    "        label_encoders['NflId'].fit(df['NflId'])\n",
    "    try:\n",
    "        df['NflId'] = label_encoders['NflId'].transform(df['NflId'])\n",
    "    except:\n",
    "        df['NflId'] = np.nan\n",
    "       \n",
    "    team_dict = {\n",
    "        'away': 0,\n",
    "        'home': 1\n",
    "    }\n",
    "    df['Team'] = df['Team'].map(team_dict)\n",
    "    season_dict = {\n",
    "        2017: 0,\n",
    "        2018: 1\n",
    "    }\n",
    "    df['Season'] = df['Season'].map(season_dict)\n",
    "    df = groupby_playid(df, is_training)\n",
    "    \n",
    "    df = df.drop(['Season', 'Temperature', 'Humidity'], axis = 1)\n",
    "    \n",
    "    if is_training:\n",
    "        df = df.apply(lambda group: group.interpolate(limit_direction='both'))\n",
    "    \n",
    "    df['WindDirection'] = df['WindDirection'].fillna(method='backfill')\n",
    "    df['WindSpeed'] = df['WindSpeed'].fillna(method='backfill')\n",
    "    df['GameWeather'] = df['GameWeather'].fillna(method='backfill')\n",
    "    df['StadiumType'] = df['StadiumType'].fillna(method='backfill')\n",
    "    df['FieldPosition'] = df['FieldPosition'].fillna(method='backfill')\n",
    "    df['OffenseFormation'] = df['OffenseFormation'].fillna(method='backfill')\n",
    "    \n",
    "    df['GameClock'] = pd.to_datetime(df['GameClock'])\n",
    "    df['TimeHandoff'] = pd.to_datetime(df['TimeHandoff'])\n",
    "    df['TimeSnap'] = pd.to_datetime(df['TimeSnap'])\n",
    "    \n",
    "    df = extract_timestamp(df, 'GameClock')\n",
    "    df = extract_timestamp(df, 'TimeHandoff')\n",
    "    df = extract_timestamp(df, 'TimeSnap')\n",
    "    df = df.drop(['GameClock', 'TimeHandoff', 'TimeSnap'], axis=1)\n",
    "    \n",
    "    df = encode_cyclic_feature(df, 'GameClockHour', 24)\n",
    "    df = encode_cyclic_feature(df, 'GameClockMinute', 60)\n",
    "    df = encode_cyclic_feature(df, 'GameClockSecond', 60)\n",
    "    \n",
    "    df = encode_cyclic_feature(df, 'TimeHandoffHour', 24)\n",
    "    df = encode_cyclic_feature(df, 'TimeHandoffMinute', 60)\n",
    "    df = encode_cyclic_feature(df, 'TimeHandoffSecond', 60)\n",
    "    \n",
    "    df = encode_cyclic_feature(df, 'TimeSnapHour', 24)\n",
    "    df = encode_cyclic_feature(df, 'TimeSnapMinute', 60)\n",
    "    df = encode_cyclic_feature(df, 'TimeSnapSecond', 60)\n",
    "    \n",
    "    def transform_game_weather(x):\n",
    "        x = str(x).lower()\n",
    "        if 'indoor' in x:\n",
    "            return  'indoor'\n",
    "        elif 'cloud' in x or 'coudy' in x or 'clouidy' in x:\n",
    "            return 'cloudy'\n",
    "        elif 'rain' in x or 'shower' in x:\n",
    "            return 'rain'\n",
    "        elif 'sunny' in x:\n",
    "            return 'sunny'\n",
    "        elif 'clear' in x:\n",
    "            return 'clear'\n",
    "        elif 'cold' in x or 'cool' in x:\n",
    "            return 'cool'\n",
    "        elif 'snow' in x:\n",
    "            return 'snow'\n",
    "        return x\n",
    "    \n",
    "    df['GameWeather'] = df['GameWeather'].apply(lambda row: transform_game_weather(row))\n",
    "    \n",
    "    categorical_features = ['PossessionTeam', 'FieldPosition', 'OffenseFormation', 'PlayDirection', 'HomeTeamAbbr', \n",
    "                        'VisitorTeamAbbr', 'NflId','Stadium', 'Location', 'GameWeather'] + get_player_specific_cols(['Position', 'PlayerCollegeName', 'NflIdRusher'])\n",
    "    \n",
    "    for col in get_player_specific_cols(['PlayerHeight']):\n",
    "        df[col] = df[col].apply(lambda x: height_to_inches(x))\n",
    "    \n",
    "    for col in get_player_specific_cols(['PlayerBirthDate']):\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "        df[col] = bdate_to_age(df[col])\n",
    "    \n",
    "    for cat in categorical_features:\n",
    "        if is_training:\n",
    "            label_encoders[cat] = LabelEncoder()\n",
    "            label_encoders[cat].fit(df[cat])\n",
    "        try:\n",
    "            df[cat] = label_encoders[cat].transform(df[cat])\n",
    "        except Exception as e:\n",
    "            df[cat] = np.nan # Put NaN in case when any unseen label is found in testing dataset.\n",
    "            \n",
    "        \n",
    "#     offense_groups = ['QB', 'RB', 'OL', 'FB', 'WR', 'TE']\n",
    "#     defense_groups = ['DL', 'LB', 'CB', 'S']\n",
    "    \n",
    "#     offense_dicts = get_grouping_dict(df, 'OffensePersonnel')\n",
    "#     defense_dicts = get_grouping_dict(df, 'DefensePersonnel')\n",
    "    \n",
    "#     offense_grps_df = pd.DataFrame(offense_dicts).rename(columns={'OL': 'OL_offense', 'DL': 'DL_offense', 'LB': 'LB_offense', 'DB': 'DB_offense'}).fillna(0).astype(int)\n",
    "#     defense_grps_df = pd.DataFrame(defense_dicts).rename(columns={'OL': 'OL_defense', 'DL': 'DL_defense', 'LB': 'LB_defense', 'DB': 'DB_defense'}).fillna(0).astype(int)\n",
    "    \n",
    "#     df = pd.concat([df, offense_grps_df, defense_grps_df], axis=1)\n",
    "    df = df.drop(['OffensePersonnel', 'DefensePersonnel'], axis=1)\n",
    "    \n",
    "    try:\n",
    "        df['NflIdRusher'] = label_encoders['NflId'].transform(df['NflIdRusher'])\n",
    "    except:\n",
    "        df['NflIdRusher'] = np.nan\n",
    "        \n",
    "    wind_directions = ['N', 'E', 'S', 'W', 'NE', 'SE', 'SW', 'NW', 'NNE', 'ENE', 'ESE', 'SSE', 'SSW', 'WSW', 'WNW', 'NNW']  # https://www.quora.com/What-is-the-definition-of-SSW-wind-direction\n",
    "    \n",
    "    df.loc[df['WindSpeed'].isin(wind_directions), 'WindSpeed'] = np.nan\n",
    "    df.loc[~df['WindDirection'].isin(wind_directions), 'WindDirection'] = np.nan\n",
    "    \n",
    "    df['WindDirection'] = df['WindDirection'].fillna(method='backfill')\n",
    "    df['WindSpeed'] = df['WindSpeed'].fillna(method='backfill')\n",
    "    \n",
    "    if is_training:\n",
    "        label_encoders['WindDirection'] = LabelEncoder()\n",
    "        label_encoders['WindDirection'].fit(df['WindDirection'])\n",
    "    try:\n",
    "        df['WindDirection'] = label_encoders['WindDirection'].transform(df['WindDirection'])\n",
    "    except Exception as e:\n",
    "        df['WindDirection'] = np.nan\n",
    "    \n",
    "    def transform_windspeed(speed):\n",
    "        speed = str(speed)\n",
    "        if 'MPH' in speed or 'mph' in speed or 'MPh' in speed:\n",
    "            speed = speed.replace('MPH', '').strip()\n",
    "            speed = speed.replace('MPH', '').strip()\n",
    "            speed = speed.replace('MPh', '').strip()\n",
    "        if '-' in speed:\n",
    "            return (float(speed.split('-')[0]) + float(speed.split('-')[1]))/2\n",
    "        try:\n",
    "            return float(speed)\n",
    "        except:\n",
    "            return 10 # https://sciencing.com/average-daily-wind-speed-24011.html\n",
    "        \n",
    "    df['WindSpeed'] = df['WindSpeed'].apply(lambda speed: transform_windspeed(speed))\n",
    "    \n",
    "    beaufort = [(0, 0, 0.3), (1, 0.3, 1.6), (2, 1.6, 3.4), (3, 3.4, 5.5), (4, 5.5, 8), \n",
    "                (5, 8, 10.8), (6, 10.8, 13.9), (7, 13.9, 17.2), (8, 17.2, 20.8), \n",
    "                (9, 20.8, 24.5), (10, 24.5, 28.5), (11, 28.5, 33), (12, 33, 200)]\n",
    "\n",
    "    for item in beaufort:\n",
    "        df.loc[(df['WindSpeed']>=item[1]) & (df['WindSpeed']<item[2]), 'beaufort_scale'] = item[0]\n",
    "    \n",
    "    df['DefendersInTheBox_vs_Distance'] = df['DefendersInTheBox'] / df['Distance']\n",
    "    df['Field_eq_Possession'] = df['FieldPosition'] == df['PossessionTeam']\n",
    "    \n",
    "    # Add BMI as a feature: formula for BMI: kg/m^2\n",
    "    total_players = 22\n",
    "    \n",
    "    def get_bmi(height, weight):\n",
    "        return weight / (height ** 2) * 755\n",
    "    \n",
    "    def is_rusher(x, y):\n",
    "        return x == y\n",
    "    \n",
    "    for player in range(total_players):\n",
    "        df[f'BMI_player{player}'] = np.vectorize(get_bmi)(df[f'PlayerHeight_player{player}'], df[f'PlayerWeight_player{player}'])\n",
    "        df[f'is_rusher_player{player}'] = np.vectorize(is_rusher)(df['NflId'], df[f'NflIdRusher_player{player}'])\n",
    "\n",
    "    # Cleaning the Turf to Natural and artificial\n",
    "    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n",
    "    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', \n",
    "            'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', \n",
    "            'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n",
    "            'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', \n",
    "            'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n",
    "\n",
    "    df['Turf'] = df['Turf'].map(Turf)\n",
    "    df['Turf'] = df['Turf'] == 'Natural'\n",
    "    \n",
    "    def clean_StadiumType(txt):\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "        txt = txt.lower()\n",
    "        txt = ''.join([c for c in txt if c not in punctuation])\n",
    "        txt = re.sub(' +', ' ', txt)\n",
    "        txt = txt.strip()\n",
    "        txt = txt.replace('outside', 'outdoor')\n",
    "        txt = txt.replace('outdor', 'outdoor')\n",
    "        txt = txt.replace('outddors', 'outdoor')\n",
    "        txt = txt.replace('outdoors', 'outdoor')\n",
    "        txt = txt.replace('oudoor', 'outdoor')\n",
    "        txt = txt.replace('indoors', 'indoor')\n",
    "        txt = txt.replace('ourdoor', 'outdoor')\n",
    "        txt = txt.replace('retractable', 'rtr.')\n",
    "        return txt\n",
    "        \n",
    "    df['StadiumType'] = df['StadiumType'].apply(clean_StadiumType)\n",
    "    \n",
    "    def transform_StadiumType(txt):\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "        if 'outdoor' in txt or 'open' in txt:\n",
    "            return 1\n",
    "        if 'indoor' in txt or 'closed' in txt:\n",
    "            return 0\n",
    "\n",
    "        return np.nan\n",
    "    \n",
    "    df['StadiumType'] = df['StadiumType'].apply(transform_StadiumType)\n",
    "    \n",
    "    # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112173#latest-647309\n",
    "#     df['JerseyNumberGrouped'] = df['JerseyNumber'] // 10\n",
    "    \n",
    "    if is_training:\n",
    "        return df, label_encoders\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23171/23171 [02:34<00:00, 150.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min, sys: 8.87 s, total: 3min 9s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df, label_encoders = feature_engineering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 19.445999145507812 Mb (73.93352831171615% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = reduce_mem_usage(train_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature_cols = ['GameId', 'PlayId'] + get_player_specific_cols(['DisplayName', 'JerseyNumber'])\n",
    "target_col = ['Yards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(non_feature_cols+target_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(Y_train.values.reshape(-1, 1))\n",
    "Y_train = scaler.transform(Y_train.values.reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is training ready. Let's train a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 666\n",
    "# n_folds = 10\n",
    "# models, y_valid_pred = [], np.zeros(len(X_train))\n",
    "# lgb_params={\n",
    "#     'learning_rate': 0.01,\n",
    "#     'objective': 'regression',\n",
    "#     'n_estimators': 1000,\n",
    "#     'num_leaves': 20,\n",
    "#     'metric': 'rmse',\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'feature_fraction': 0.7\n",
    "# }\n",
    "\n",
    "# kf = KFold(n_splits = n_folds, shuffle=False, random_state=seed)\n",
    "\n",
    "# for train_idx, val_idx in kf.split(X_train, Y_train):\n",
    "#     x_train, y_train = X_train.iloc[train_idx, :], Y_train[train_idx]\n",
    "#     x_val, y_val = X_train.iloc[val_idx, :], Y_train[val_idx]\n",
    "    \n",
    "#     training_data = lgb.Dataset(x_train, label=y_train)\n",
    "#     val_data = lgb.Dataset(x_val, label=y_val)\n",
    "    \n",
    "#     regressor = lgb.LGBMRegressor(**lgb_params)\n",
    "#     regressor.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=100, verbose=100)\n",
    "    \n",
    "#     y_valid_pred[val_idx] += regressor.predict(x_val, num_iteration=regressor.best_iteration_)\n",
    "#     models.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0075494\ttest: 0.9073799\tbest: 0.9073799 (0)\ttotal: 96.2ms\tremaining: 3m 12s\n",
      "100:\tlearn: 0.9891235\ttest: 0.8983496\tbest: 0.8983496 (100)\ttotal: 3.54s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.9780680\ttest: 0.8967013\tbest: 0.8966706 (189)\ttotal: 6.94s\tremaining: 1m 2s\n",
      "300:\tlearn: 0.9681501\ttest: 0.8964705\tbest: 0.8963171 (253)\ttotal: 10.3s\tremaining: 58.2s\n",
      "400:\tlearn: 0.9586537\ttest: 0.8966031\tbest: 0.8961904 (311)\ttotal: 13.7s\tremaining: 54.6s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.8961903993\n",
      "bestIteration = 311\n",
      "\n",
      "Shrink model to first 312 iterations.\n",
      "0:\tlearn: 0.9889402\ttest: 1.1101420\tbest: 1.1101420 (0)\ttotal: 37.4ms\tremaining: 1m 14s\n",
      "100:\tlearn: 0.9716055\ttest: 1.1054301\tbest: 1.1054301 (100)\ttotal: 3.44s\tremaining: 1m 4s\n",
      "200:\tlearn: 0.9611218\ttest: 1.1044643\tbest: 1.1044461 (198)\ttotal: 6.81s\tremaining: 1m\n",
      "300:\tlearn: 0.9512620\ttest: 1.1039985\tbest: 1.1039985 (300)\ttotal: 10.2s\tremaining: 57.6s\n",
      "400:\tlearn: 0.9418096\ttest: 1.1037668\tbest: 1.1036134 (342)\ttotal: 13.6s\tremaining: 54.1s\n",
      "500:\tlearn: 0.9320573\ttest: 1.1033650\tbest: 1.1033650 (500)\ttotal: 16.8s\tremaining: 50.4s\n",
      "600:\tlearn: 0.9223972\ttest: 1.1029485\tbest: 1.1028740 (589)\ttotal: 19.9s\tremaining: 46.3s\n",
      "700:\tlearn: 0.9134839\ttest: 1.1024604\tbest: 1.1024284 (694)\ttotal: 23s\tremaining: 42.5s\n",
      "800:\tlearn: 0.9042981\ttest: 1.1024151\tbest: 1.1024064 (798)\ttotal: 26.1s\tremaining: 39s\n",
      "900:\tlearn: 0.8950307\ttest: 1.1024711\tbest: 1.1023244 (805)\ttotal: 29.2s\tremaining: 35.7s\n",
      "1000:\tlearn: 0.8859579\ttest: 1.1025258\tbest: 1.1022832 (933)\ttotal: 32.5s\tremaining: 32.4s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.102283229\n",
      "bestIteration = 933\n",
      "\n",
      "Shrink model to first 934 iterations.\n",
      "0:\tlearn: 1.0008593\ttest: 0.9857941\tbest: 0.9857941 (0)\ttotal: 35.9ms\tremaining: 1m 11s\n",
      "100:\tlearn: 0.9836045\ttest: 0.9765157\tbest: 0.9765157 (100)\ttotal: 3.57s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.9729987\ttest: 0.9750324\tbest: 0.9750324 (200)\ttotal: 7.01s\tremaining: 1m 2s\n",
      "300:\tlearn: 0.9632512\ttest: 0.9748230\tbest: 0.9747466 (284)\ttotal: 10.4s\tremaining: 58.6s\n",
      "400:\tlearn: 0.9539276\ttest: 0.9750151\tbest: 0.9747466 (284)\ttotal: 13.8s\tremaining: 55s\n",
      "500:\tlearn: 0.9433318\ttest: 0.9744448\tbest: 0.9743942 (495)\ttotal: 17.1s\tremaining: 51.1s\n",
      "600:\tlearn: 0.9324985\ttest: 0.9739727\tbest: 0.9739727 (600)\ttotal: 20.3s\tremaining: 47.2s\n",
      "700:\tlearn: 0.9226527\ttest: 0.9740372\tbest: 0.9739727 (600)\ttotal: 23.4s\tremaining: 43.4s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9739726621\n",
      "bestIteration = 600\n",
      "\n",
      "Shrink model to first 601 iterations.\n",
      "0:\tlearn: 1.0002215\ttest: 0.9927288\tbest: 0.9927288 (0)\ttotal: 35.5ms\tremaining: 1m 10s\n",
      "100:\tlearn: 0.9819192\ttest: 0.9863995\tbest: 0.9863317 (93)\ttotal: 3.47s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9711874\ttest: 0.9847187\tbest: 0.9846882 (199)\ttotal: 6.86s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9612359\ttest: 0.9840593\tbest: 0.9840469 (295)\ttotal: 10.2s\tremaining: 57.5s\n",
      "400:\tlearn: 0.9521103\ttest: 0.9841185\tbest: 0.9840030 (357)\ttotal: 13.6s\tremaining: 54.1s\n",
      "500:\tlearn: 0.9422588\ttest: 0.9839170\tbest: 0.9839153 (499)\ttotal: 16.9s\tremaining: 50.4s\n",
      "600:\tlearn: 0.9319532\ttest: 0.9842018\tbest: 0.9839153 (499)\ttotal: 20.1s\tremaining: 46.8s\n",
      "700:\tlearn: 0.9211037\ttest: 0.9841739\tbest: 0.9839138 (631)\ttotal: 23.3s\tremaining: 43.2s\n",
      "800:\tlearn: 0.9107748\ttest: 0.9839079\tbest: 0.9837305 (757)\ttotal: 26.5s\tremaining: 39.7s\n",
      "900:\tlearn: 0.9004653\ttest: 0.9832362\tbest: 0.9830421 (888)\ttotal: 29.7s\tremaining: 36.3s\n",
      "1000:\tlearn: 0.8906523\ttest: 0.9836586\tbest: 0.9830421 (888)\ttotal: 33s\tremaining: 32.9s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.983042084\n",
      "bestIteration = 888\n",
      "\n",
      "Shrink model to first 889 iterations.\n",
      "0:\tlearn: 1.0048018\ttest: 0.9403165\tbest: 0.9403165 (0)\ttotal: 36.6ms\tremaining: 1m 13s\n",
      "100:\tlearn: 0.9867172\ttest: 0.9320896\tbest: 0.9320734 (98)\ttotal: 3.47s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9760507\ttest: 0.9305805\tbest: 0.9305689 (198)\ttotal: 6.83s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9658214\ttest: 0.9300628\tbest: 0.9300538 (298)\ttotal: 10.2s\tremaining: 57.6s\n",
      "400:\tlearn: 0.9554307\ttest: 0.9298415\tbest: 0.9297874 (395)\ttotal: 13.6s\tremaining: 54.1s\n",
      "500:\tlearn: 0.9455878\ttest: 0.9294457\tbest: 0.9294457 (500)\ttotal: 16.9s\tremaining: 50.4s\n",
      "600:\tlearn: 0.9346079\ttest: 0.9294403\tbest: 0.9293515 (572)\ttotal: 20s\tremaining: 46.6s\n",
      "700:\tlearn: 0.9242573\ttest: 0.9292953\tbest: 0.9291325 (678)\ttotal: 23.1s\tremaining: 42.9s\n",
      "800:\tlearn: 0.9139480\ttest: 0.9298163\tbest: 0.9291325 (678)\ttotal: 26.3s\tremaining: 39.3s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9291324739\n",
      "bestIteration = 678\n",
      "\n",
      "Shrink model to first 679 iterations.\n",
      "0:\tlearn: 1.0087560\ttest: 0.8925709\tbest: 0.8925709 (0)\ttotal: 37.4ms\tremaining: 1m 14s\n",
      "100:\tlearn: 0.9912206\ttest: 0.8842687\tbest: 0.8842687 (100)\ttotal: 3.59s\tremaining: 1m 7s\n",
      "200:\tlearn: 0.9806909\ttest: 0.8818469\tbest: 0.8818469 (200)\ttotal: 7.14s\tremaining: 1m 3s\n",
      "300:\tlearn: 0.9707665\ttest: 0.8809606\tbest: 0.8809149 (297)\ttotal: 10.6s\tremaining: 1m\n",
      "400:\tlearn: 0.9614684\ttest: 0.8807297\tbest: 0.8807065 (395)\ttotal: 14.4s\tremaining: 57.5s\n",
      "500:\tlearn: 0.9516398\ttest: 0.8801074\tbest: 0.8800518 (494)\ttotal: 18s\tremaining: 53.9s\n",
      "600:\tlearn: 0.9413803\ttest: 0.8798258\tbest: 0.8798258 (600)\ttotal: 21.3s\tremaining: 49.5s\n",
      "700:\tlearn: 0.9304963\ttest: 0.8797945\tbest: 0.8796222 (672)\ttotal: 24.5s\tremaining: 45.3s\n",
      "800:\tlearn: 0.9196161\ttest: 0.8793836\tbest: 0.8793693 (788)\ttotal: 27.8s\tremaining: 41.5s\n",
      "900:\tlearn: 0.9089131\ttest: 0.8792828\tbest: 0.8790642 (853)\ttotal: 31s\tremaining: 37.8s\n",
      "1000:\tlearn: 0.8988927\ttest: 0.8792099\tbest: 0.8790642 (853)\ttotal: 34.3s\tremaining: 34.2s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.8790642157\n",
      "bestIteration = 853\n",
      "\n",
      "Shrink model to first 854 iterations.\n",
      "0:\tlearn: 1.0079440\ttest: 0.9028543\tbest: 0.9028543 (0)\ttotal: 36.2ms\tremaining: 1m 12s\n",
      "100:\tlearn: 0.9904579\ttest: 0.8920691\tbest: 0.8920691 (100)\ttotal: 3.51s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9795898\ttest: 0.8909000\tbest: 0.8908982 (198)\ttotal: 6.89s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9695686\ttest: 0.8906144\tbest: 0.8903987 (269)\ttotal: 10.2s\tremaining: 57.8s\n",
      "400:\tlearn: 0.9599376\ttest: 0.8903467\tbest: 0.8902763 (386)\ttotal: 13.6s\tremaining: 54.2s\n",
      "500:\tlearn: 0.9494118\ttest: 0.8897678\tbest: 0.8895734 (465)\ttotal: 16.9s\tremaining: 50.7s\n",
      "600:\tlearn: 0.9389838\ttest: 0.8900445\tbest: 0.8895734 (465)\ttotal: 20.2s\tremaining: 46.9s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.8895734424\n",
      "bestIteration = 465\n",
      "\n",
      "Shrink model to first 466 iterations.\n",
      "0:\tlearn: 0.9968062\ttest: 1.0294786\tbest: 1.0294786 (0)\ttotal: 37ms\tremaining: 1m 14s\n",
      "100:\tlearn: 0.9788164\ttest: 1.0188234\tbest: 1.0188234 (100)\ttotal: 3.47s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9678904\ttest: 1.0161899\tbest: 1.0161899 (200)\ttotal: 6.91s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9571649\ttest: 1.0152269\tbest: 1.0151819 (298)\ttotal: 10.3s\tremaining: 57.9s\n",
      "400:\tlearn: 0.9475188\ttest: 1.0143487\tbest: 1.0142651 (389)\ttotal: 13.7s\tremaining: 54.5s\n",
      "500:\tlearn: 0.9379690\ttest: 1.0138885\tbest: 1.0137936 (489)\ttotal: 17s\tremaining: 50.8s\n",
      "600:\tlearn: 0.9273211\ttest: 1.0136660\tbest: 1.0135953 (559)\ttotal: 20.1s\tremaining: 46.8s\n",
      "700:\tlearn: 0.9164065\ttest: 1.0136526\tbest: 1.0133373 (674)\ttotal: 23.3s\tremaining: 43.1s\n",
      "800:\tlearn: 0.9059235\ttest: 1.0135406\tbest: 1.0133373 (674)\ttotal: 26.5s\tremaining: 39.6s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.013337319\n",
      "bestIteration = 674\n",
      "\n",
      "Shrink model to first 675 iterations.\n",
      "0:\tlearn: 0.9994939\ttest: 1.0010108\tbest: 1.0010108 (0)\ttotal: 32.6ms\tremaining: 1m 5s\n",
      "100:\tlearn: 0.9815216\ttest: 0.9905749\tbest: 0.9905749 (100)\ttotal: 3.48s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9703898\ttest: 0.9900028\tbest: 0.9899746 (181)\ttotal: 6.91s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9601919\ttest: 0.9892198\tbest: 0.9891548 (270)\ttotal: 10.3s\tremaining: 57.9s\n",
      "400:\tlearn: 0.9503478\ttest: 0.9888542\tbest: 0.9888542 (400)\ttotal: 13.6s\tremaining: 54.3s\n",
      "500:\tlearn: 0.9400114\ttest: 0.9884352\tbest: 0.9883809 (497)\ttotal: 16.9s\tremaining: 50.5s\n",
      "600:\tlearn: 0.9290521\ttest: 0.9888191\tbest: 0.9883809 (497)\ttotal: 20.1s\tremaining: 46.7s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9883808506\n",
      "bestIteration = 497\n",
      "\n",
      "Shrink model to first 498 iterations.\n",
      "0:\tlearn: 0.9977633\ttest: 1.0196920\tbest: 1.0196920 (0)\ttotal: 39.1ms\tremaining: 1m 18s\n",
      "100:\tlearn: 0.9800285\ttest: 1.0100421\tbest: 1.0100421 (100)\ttotal: 3.41s\tremaining: 1m 4s\n",
      "200:\tlearn: 0.9694028\ttest: 1.0093494\tbest: 1.0093494 (200)\ttotal: 6.81s\tremaining: 1m\n",
      "300:\tlearn: 0.9594081\ttest: 1.0093549\tbest: 1.0092355 (219)\ttotal: 10.1s\tremaining: 57.2s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.009235486\n",
      "bestIteration = 219\n",
      "\n",
      "Shrink model to first 220 iterations.\n",
      "0:\tlearn: 0.9810483\ttest: 1.1854678\tbest: 1.1854678 (0)\ttotal: 32.6ms\tremaining: 1m 5s\n",
      "100:\tlearn: 0.9641502\ttest: 1.1783896\tbest: 1.1783896 (100)\ttotal: 3.49s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.9537565\ttest: 1.1771368\tbest: 1.1770460 (191)\ttotal: 6.88s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9437589\ttest: 1.1769524\tbest: 1.1765990 (256)\ttotal: 10.2s\tremaining: 57.7s\n",
      "400:\tlearn: 0.9349689\ttest: 1.1770224\tbest: 1.1765990 (256)\ttotal: 13.6s\tremaining: 54.2s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 1.176599038\n",
      "bestIteration = 256\n",
      "\n",
      "Shrink model to first 257 iterations.\n",
      "0:\tlearn: 1.0005331\ttest: 0.9897787\tbest: 0.9897787 (0)\ttotal: 43.1ms\tremaining: 1m 26s\n",
      "100:\tlearn: 0.9824893\ttest: 0.9809084\tbest: 0.9809084 (100)\ttotal: 3.51s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.9720847\ttest: 0.9800275\tbest: 0.9799995 (194)\ttotal: 6.89s\tremaining: 1m 1s\n",
      "300:\tlearn: 0.9624661\ttest: 0.9799745\tbest: 0.9798204 (232)\ttotal: 10.2s\tremaining: 57.7s\n",
      "400:\tlearn: 0.9524394\ttest: 0.9795711\tbest: 0.9795401 (398)\ttotal: 13.6s\tremaining: 54.4s\n",
      "500:\tlearn: 0.9424905\ttest: 0.9793574\tbest: 0.9791849 (482)\ttotal: 17s\tremaining: 50.8s\n",
      "600:\tlearn: 0.9319995\ttest: 0.9795605\tbest: 0.9791849 (482)\ttotal: 20.2s\tremaining: 46.9s\n",
      "Stopped by overfitting detector  (150 iterations wait)\n",
      "\n",
      "bestTest = 0.9791848919\n",
      "bestIteration = 482\n",
      "\n",
      "Shrink model to first 483 iterations.\n"
     ]
    }
   ],
   "source": [
    "seed = 666\n",
    "n_folds = 12\n",
    "models, y_valid_pred = [], np.zeros(len(X_train))\n",
    "\n",
    "kf = KFold(n_splits = n_folds, shuffle=False, random_state=seed)\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train, Y_train):\n",
    "    x_train, y_train = X_train.iloc[train_idx, :], Y_train[train_idx]\n",
    "    x_val, y_val = X_train.iloc[val_idx, :], Y_train[val_idx]\n",
    "\n",
    "    model = CatBoostRegressor(loss_function=\"RMSE\",\n",
    "                               eval_metric=\"RMSE\",\n",
    "                               task_type=\"CPU\",\n",
    "                               learning_rate=0.02,\n",
    "                               iterations=2000,\n",
    "                               l2_leaf_reg=5,\n",
    "                               random_seed=42,\n",
    "                               od_type=\"Iter\",\n",
    "                               depth=6,\n",
    "                               early_stopping_rounds=150,\n",
    "                               border_count=32\n",
    "                              )\n",
    "\n",
    "    train_data = Pool(x_train, y_train)\n",
    "    valid_data = Pool(x_val, y_val)\n",
    "\n",
    "    regressor = model.fit(train_data,\n",
    "                        eval_set=valid_data,\n",
    "                        use_best_model=True,\n",
    "                        verbose=100)\n",
    "    \n",
    "    y_valid_pred[val_idx] += regressor.predict(x_val)\n",
    "    models.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.015527320474453753\n"
     ]
    }
   ],
   "source": [
    "# Reference: https://www.kaggle.com/hukuda222/nfl-simple-model-using-lightgbm\n",
    "y_pred = np.zeros((len(X_train),199))\n",
    "y_ans = np.zeros((len(X_train),199))\n",
    "\n",
    "for i,p in enumerate(np.round(scaler.inverse_transform(y_valid_pred))):\n",
    "    p+=99\n",
    "    for j in range(199):\n",
    "        if j>=p+10:\n",
    "            y_pred[i][j]=1.0\n",
    "        elif j>=p-10:\n",
    "            y_pred[i][j]=(j+10-p)*0.05\n",
    "\n",
    "for i,p in enumerate(scaler.inverse_transform(Y_train)):\n",
    "    p+=99\n",
    "    for j in range(199):\n",
    "        if j>=p:\n",
    "            y_ans[i][j]=1.0\n",
    "\n",
    "print(\"validation score:\",np.sum(np.power(y_pred-y_ans,2))/(199*((len(X_train)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pickle', 'wb') as handle:\n",
    "    pickle.dump(models, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoders.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoders, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='models.pickle' target='_blank'>models.pickle</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/models.pickle"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink, FileLinks\n",
    "FileLink('models.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='label_encoders.pickle' target='_blank'>label_encoders.pickle</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/label_encoders.pickle"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('label_encoders.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models.pickle', 'rb') as handle:\n",
    "    models = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoders.pickle', 'rb') as handle:\n",
    "    label_encoders = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [01:46,  1.26it/s]/opt/conda/lib/python3.6/site-packages/numpy/lib/arraysetops.py:565: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "3438it [46:59,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "non_feature_cols = ['GameId', 'PlayId'] + get_player_specific_cols(['DisplayName', 'JerseyNumber'])\n",
    "for (test_df, sample_prediction_df) in tqdm(env.iter_test(), position=0, leave=True):\n",
    "    test_df = feature_engineering(test_df, False, label_encoders)\n",
    "    test_df = test_df.drop(non_feature_cols, axis=1)\n",
    "    y_pred = np.zeros(199)        \n",
    "    y_pred_p = np.sum(np.round(scaler.inverse_transform([model.predict(test_df)[0] for model in models])))/n_folds\n",
    "    y_pred_p += 99\n",
    "    for j in range(199):\n",
    "        if j>=y_pred_p+10:\n",
    "            y_pred[j]=1.0\n",
    "        elif j>=y_pred_p-10:\n",
    "            y_pred[j]=(j+10-y_pred_p)*0.05\n",
    "    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\n",
    "env.write_submission_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
