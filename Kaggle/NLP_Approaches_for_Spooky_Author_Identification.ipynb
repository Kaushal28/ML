{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Approaches for Spooky Author Identification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuF8MX-UwFlb",
        "colab_type": "code",
        "outputId": "13b52ecf-3966-41d2-b8aa-c01b5f5e81fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# # Download required dataset\n",
        "# !gdown https://drive.google.com/uc?id=1Hs6daoHoz_urLbGsRsapmI0pNjUgfLR9\n",
        "# !unzip spooky-author-identification.zip\n",
        "# !rm -rf spooky-author-identification.zip\n",
        "# !rm -rf sample_data\n",
        "# !unzip train.zip\n",
        "# !unzip test.zip\n",
        "# !unzip sample_submission.zip\n",
        "# !rm -rf test.zip train.zip\n",
        "# !rm -rf sample_submission.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Hs6daoHoz_urLbGsRsapmI0pNjUgfLR9\n",
            "To: /content/spooky-author-identification.zip\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\r100% 1.90M/1.90M [00:00<00:00, 61.2MB/s]\n",
            "Archive:  spooky-author-identification.zip\n",
            "  inflating: train.zip               \n",
            "  inflating: sample_submission.zip   \n",
            "  inflating: test.zip                \n",
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  sample_submission.zip\n",
            "  inflating: sample_submission.csv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eXymkd-wgH6",
        "colab_type": "code",
        "outputId": "e38b6bdc-0fce-42b8-8597-595dd137dc58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCLsamGqv0C7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM, GRU\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSrORdRIwCrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrSxjjJgwl2h",
        "colab_type": "code",
        "outputId": "74f0d8f2-c5bd-47a3-ec86-dc925b7bf4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAC5cP2Yw-sB",
        "colab_type": "code",
        "outputId": "2f90f44a-ff91-4dfd-ba7e-c166fe75b50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id02310</td>\n",
              "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id24541</td>\n",
              "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id00134</td>\n",
              "      <td>And when they had broken down the frail door t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27757</td>\n",
              "      <td>While I was thinking how I should possibly man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id04081</td>\n",
              "      <td>I am not sure to what limit his knowledge may ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text\n",
              "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
              "1  id24541  If a fire wanted fanning, it could readily be ...\n",
              "2  id00134  And when they had broken down the frail door t...\n",
              "3  id27757  While I was thinking how I should possibly man...\n",
              "4  id04081  I am not sure to what limit his knowledge may ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stW_J9FxxArF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lbl_enc = preprocessing.LabelEncoder()\n",
        "y = lbl_enc.fit_transform(train_df.author.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unim1YQI10yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spit_submission_zip(predictions, test_df, file_name):\n",
        "    submission_df = pd.concat([test_df['id'], pd.DataFrame(predictions, columns = ['EAP', 'HPL', 'MWS'])], axis = 1)\n",
        "    submission_df.to_csv('predictions.csv', index=False)\n",
        "    !zip {file_name}.zip predictions.csv\n",
        "    !rm -rf predictions.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF64gh4yyMie",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression with TF-IDF as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYAnePdWyEXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Always start with these features. They work (almost) everytime!\n",
        "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "# Fitting TF-IDF to training-set\n",
        "tfv.fit(train_df['text'])\n",
        "xtrain_tfv =  tfv.transform(train_df['text']) \n",
        "xtest_tfv = tfv.transform(test_df['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLXx1unOygRR",
        "colab_type": "code",
        "outputId": "73e8bc73-1ebf-4ce0-eacc-9b8fd99d511c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Fitting a simple Logistic Regression on TFIDF\n",
        "clf = LogisticRegression(C = 3)\n",
        "clf.fit(xtrain_tfv, y)\n",
        "predictions = clf.predict_proba(xtest_tfv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FcAW0lo2kFy",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.5174 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUoHN1SKzTr1",
        "colab_type": "code",
        "outputId": "e8df5375-5663-4183-c867-626d55883c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'TFIDF-LR')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions.csv (deflated 54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keoiMMs923Se",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression with Word Counts as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-DYUXJE2Biw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w+',\n",
        "            ngram_range=(1, 3), stop_words = 'english')\n",
        "\n",
        "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
        "ctv.fit(train_df['text'])\n",
        "xtrain_ctv =  ctv.transform(train_df['text']) \n",
        "xvalid_ctv = ctv.transform(test_df['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DhVRJwmBIbt",
        "colab_type": "code",
        "outputId": "578e891d-cce7-46a6-99b0-d35026e849df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Fitting a simple Logistic Regression on Counts\n",
        "clf = LogisticRegression(C = 3)\n",
        "clf.fit(xtrain_ctv, y)\n",
        "predictions = clf.predict_proba(xvalid_ctv)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhtTcj0cCP9V",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.5043 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJTinQaBBVkt",
        "colab_type": "code",
        "outputId": "a1af013a-25a4-40ac-c31d-e4f07540ea37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'CV-LR')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions.csv (deflated 54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGiX0s0xCmv9",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes with TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCbjrvwsBX0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting a simple Naive Bayes on TFIDF\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_tfv, y)\n",
        "predictions = clf.predict_proba(xtest_tfv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-cpjuOtDf08",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.5645 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMcyn-8aDKOo",
        "colab_type": "code",
        "outputId": "419b0c6e-1f27-41e3-bcef-442d29d7ca31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'TFIDF-NB')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions.csv (deflated 54%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6_b88vODmDO",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes with word cound as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTxSaPMdDNiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting a simple Naive Bayes on Counts\n",
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_ctv, y)\n",
        "predictions = clf.predict_proba(xvalid_ctv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U0jaKDBD4Hi",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.4448 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecKNstQjDwNv",
        "colab_type": "code",
        "outputId": "75597451-d1ea-4e24-e11f-f82e79283212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'CV-NB')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions.csv (deflated 55%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu5pd-GKELYy",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machine (SVM) with TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hlx88BJmDz79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First apply dimensionality reduction. Here TF-IDF is sparse matrix, so PCA won't work. Instead apply truncated SVD\n",
        "svd = decomposition.TruncatedSVD(n_components=150)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xvalid_svd = svd.transform(xtest_tfv)\n",
        "\n",
        "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srBl2QHFFWWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting a simple SVM\n",
        "# clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
        "# clf.fit(xtrain_svd_scl, y)\n",
        "# predictions = clf.predict_proba(xvalid_svd_scl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAlse5P3Fa74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# spit_submission_zip(predictions, test_df, 'TFIDF-SVD-SVM')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzhQSKaDU9X_",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost with TF-IDF as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQGG9YkCITXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_tfv.tocsc(), y)\n",
        "predictions = clf.predict_proba(xtest_tfv.tocsc())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2DYG6cKV8M4",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.7718 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOEtXRuJVY5z",
        "colab_type": "code",
        "outputId": "da441478-ed5a-467f-9164-c58d6debff4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'TFIDF-XGBOOST')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: predictions.csv (deflated 61%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eADyJeatWeSD",
        "colab_type": "text"
      },
      "source": [
        "## XGBoost with word counts as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IlEkbUUV0XP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "clf.fit(xtrain_ctv.tocsc(), y)\n",
        "predictions = clf.predict_proba(xvalid_ctv.tocsc())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBPOfGLAhHf6",
        "colab_type": "text"
      },
      "source": [
        "### This achieves 0.7660 multiclass logloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtdV6-BuWppp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spit_submission_zip(predictions, test_df, 'CV-XGBOOST')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7w61tbXtyjb",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-LG9FsGWwu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multiclass logloss function\n",
        "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
        "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
        "    :param actual: Array containing the actual target classes\n",
        "    :param predicted: Matrix with class predictions, one probability per class\n",
        "    \"\"\"\n",
        "    # Convert 'actual' to a binary array if it's not already:\n",
        "    if len(actual.shape) == 1:\n",
        "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
        "        for i, val in enumerate(actual):\n",
        "            actual2[i, val] = 1\n",
        "        actual = actual2\n",
        "\n",
        "    clip = np.clip(predicted, eps, 1 - eps)\n",
        "    rows = actual.shape[0]\n",
        "    vsota = np.sum(actual * np.log(clip))\n",
        "    return -1.0 / rows * vsota"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd8pQXJNtfPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rJFBF0Atka5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize SVD\n",
        "svd = TruncatedSVD()\n",
        "    \n",
        "# Initialize the standard scaler \n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "# We will use logistic regression here..\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('svd_k', svd),\n",
        "                         ('scl_k', scl),\n",
        "                         ('lr_k', lr_model)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akHTrwqYuJ9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'svd_k__n_components' : [120, 180],\n",
        "              'lr_k__C': [0.1, 1.0, 10], \n",
        "              'lr_k__penalty': ['l1', 'l2']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADBISvQau1Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, y)  # we can use the full data here but im only using xtrain\n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgkvo2dQzFJC",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search on Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_64gpqFszHfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_model = MultinomialNB()\n",
        "svd = TruncatedSVD()\n",
        "scl = preprocessing.StandardScaler()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('nb', nb_model)])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {'nb__alpha': [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]}\n",
        "\n",
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, y)  # we can use the full data here but im only using xtrain. \n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojitybDq2D8X",
        "colab_type": "text"
      },
      "source": [
        "## Grid Search on XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku_SlkCjzR9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xgb = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
        "\n",
        "clf = pipeline.Pipeline([('xgb', xgb)])\n",
        "\n",
        "param_grid = {\n",
        "    'xgb__max_depth': [4, 5, 6, 7, 8],\n",
        "    'xgb__n_estimators': [140, 160, 180, 200, 220, 240],\n",
        "    'xgb__learning_rate': [0.001, 0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "model = GridSearchCV(estimator = clf, param_grid=param_grid, scoring=mll_scorer, verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, y)  # we can use the full data here but im only using xtrain. \n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnqt45_43U2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}